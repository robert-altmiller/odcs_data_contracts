resources:
  jobs:
    s4_data_contract_run_dq_rules:
      name: s4_data_contract_run_dq_rules
      tasks:
      
        - task_key: Data_Contract_DQ_Rules
          notebook_task:
            notebook_path: notebooks/s5_data_contract_dq_checks
            base_parameters:
              user_email: ${var.user_email}
              dq_folder_path: "{{params.base_path}}/${var.user_email}/odcs_data_contracts/notebooks/{{ params.dq_folder_path }}"
              running_in_workflow: True
              source_catalog: ${var.odcs_contract_source_catalog}
              source_schema: ${var.odcs_contract_source_schema}
            source: GIT
          job_cluster_key: Job_cluster
          libraries:
            - pypi:
                package: datacontract-cli[databricks]

      job_clusters:
        - job_cluster_key: Job_cluster
          new_cluster:
            cluster_name: ""
            spark_version: 15.4.x-scala2.12
            azure_attributes:
              first_on_demand: 1
              availability: SPOT_WITH_FALLBACK_AZURE
              spot_bid_max_price: -1
            node_type_id: Standard_D4ds_v5
            spark_env_vars:
              PYSPARK_PYTHON: /databricks/python3/bin/python3
            enable_elastic_disk: true
            data_security_mode: SHARED # USER_ISOLATION # SINGLE_USER
            runtime_engine: PHOTON
            num_workers: 2

      git_source:
        git_url: ${var.git_repo_url}
        git_provider: ${var.git_source}
        git_branch: ${var.branch_name}

      queue:
        enabled: true
